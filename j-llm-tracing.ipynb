{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Trace with Langfuse - Your Retrieval Augmented Question & Answering with Amazon Bedrock using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Context\n",
    "We integrate a tracing mechanism for Retreival Augmented Generation (RAG) pattern implementation. RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context. The implementation leverages the documents to provide answers to the questions. We shall use Langfuse to trace through the interactions to gain deeper insights into the working.\n",
    "\n",
    "### Challenges\n",
    "- LLM traceability is not a mere tracing of the requests for latency and processing bottlenecks. It is about understanding the prompt, input context, and refining further as required. A methodical way to unearth the insights is a challenge.\n",
    "\n",
    "### Understand the RAG working first\n",
    "\n",
    "#### Prepare documents\n",
    "Before being able to answer the questions, the documents must be processed and a stored in a document store index\n",
    "- Load the documents\n",
    "- Process and split them into smaller chunks\n",
    "- Create a numerical vector representation of each chunk using Amazon Bedrock Titan Embeddings model\n",
    "- Create an index using the chunks and the corresponding embeddings\n",
    "#### Ask question\n",
    "When the documents index is prepared, you are ready to ask the questions and relevant documents will be fetched based on the question being asked. Following steps will be executed.\n",
    "- Create an embedding of the input question\n",
    "- Compare the question embedding with the embeddings in the index\n",
    "- Fetch the (top N) relevant document chunks\n",
    "- Add those chunks as part of the context in the prompt\n",
    "- Send the prompt to the model under Amazon Bedrock\n",
    "- Get the contextual answer based on the documents retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "We are using the documents from IRS. These documents explain topics such as:\n",
    "- Original Issue Discount (OID) Instruments\n",
    "- Reporting Cash Payments of Over $10,000 to IRS\n",
    "- Employer's Tax Guide\n",
    "\n",
    "#### Who is interacting with our system?\n",
    "Alayman who doesn't have an understanding of how IRS works and if some actions have implications or not. The model will try to answer from the documents it ingested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "We are using the LangChain framework. Langfuse has integration with LangChain. So, we will be able to trace the LLM interactions.\n",
    "\n",
    "- **LLM (Large Language Model)**: Anthropic Claude V1 available through Amazon Bedrock, used to understand the document chunks and provide an answer.\n",
    "- **Embeddings Model**: Amazon Titan Embeddings available through Amazon Bedrock, used to generate embeddings (numerical representation) of the textual documents.\n",
    "- **Document Loader**: PDF Loader available through LangChain; This can load the documents from a source. We are loading the sample files from a local path. This could easily be replaced with a loader to load documents from enterprise internal systems.\n",
    "- **Vector Store**: FAISS available through LangChain; We are using this in-memory vector-store to store both the embeddings and the documents. In an enterprise context this could be replaced with a persistent store such as AWS OpenSearch, RDS Postgres with pgVector, ChromaDB, Pinecone, or Milvus.\n",
    "- **Index**: VectorIndex; The index helps to compare the input embedding and the document embeddings to find relevant document\n",
    "- **Wrapper**: wraps index, vector store, embeddings model and the LLM to abstract away the logic from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (0.2.16)\n",
      "Requirement already satisfied: pypdf==4.1.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: langchain-community in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (0.2.16)\n",
      "Requirement already satisfied: langchain-core in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (0.2.38)\n",
      "Requirement already satisfied: faiss-cpu==1.8.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: tiktoken==0.6.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (0.6.0)\n",
      "Requirement already satisfied: sqlalchemy==2.0.28 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (2.0.28)\n",
      "Requirement already satisfied: langfuse in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (2.47.0)\n",
      "Requirement already satisfied: boto3 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (1.34.162)\n",
      "Requirement already satisfied: numpy in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from faiss-cpu==1.8.0) (1.26.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from tiktoken==0.6.0) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from tiktoken==0.6.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from sqlalchemy==2.0.28) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from sqlalchemy==2.0.28) (3.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain) (0.1.116)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain) (2.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langfuse) (4.4.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langfuse) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langfuse) (0.27.2)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langfuse) (3.8)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langfuse) (1.16.0)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.162 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from boto3) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (2.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.23.2)\n",
      "Requirement already satisfied: tzdata in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-aws in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (0.1.17)\n",
      "Requirement already satisfied: boto3<1.35.0,>=1.34.131 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-aws) (1.34.162)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.33 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-aws) (0.2.38)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-aws) (1.26.4)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.162 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from boto3<1.35.0,>=1.34.131->langchain-aws) (0.10.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (0.1.116)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (2.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.33->langchain-aws) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.162->boto3<1.35.0,>=1.34.131->langchain-aws) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.162->boto3<1.35.0,>=1.34.131->langchain-aws) (2.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.33->langchain-aws) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.33->langchain-aws) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.33->langchain-aws) (2.23.2)\n",
      "Requirement already satisfied: tzdata in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.33->langchain-aws) (2024.1)\n",
      "Requirement already satisfied: anyio in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (3.8)\n",
      "Requirement already satisfied: sniffio in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3<1.35.0,>=1.34.131->langchain-aws) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/praghavs/RP_HOME/osswork/.venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.33->langchain-aws) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain pypdf==4.1.0 langchain-community langchain-core faiss-cpu==1.8.0 tiktoken==0.6.0 sqlalchemy==2.0.28 langfuse boto3\n",
    "%pip install -U langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set credentials - for langchain and for langfuse\n",
    "import os\n",
    "os.system('export AWS_PROFILE=default')\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = 'pk-lf-c8ec60a4-3f7e-4e65-8eda-09e76f796b3f'\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = 'sk-lf-0ffdfee6-4e88-4110-85ef-b6e153382c81'\n",
    "os.environ[\"LANGFUSE_HOST\"] = 'http://localhost:3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a print function\n",
    "import warnings\n",
    "import sys\n",
    "import textwrap\n",
    "import os\n",
    "from typing import Optional\n",
    "from io import StringIO\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def print_ww(*args, width: int = 100, **kwargs):\n",
    "    \"\"\"Like print(), but wraps output to `width` characters (default 100)\"\"\"\n",
    "    buffer = StringIO()\n",
    "    try:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        print(*args, **kwargs)\n",
    "        output = buffer.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = _stdout\n",
    "    for line in output.splitlines():\n",
    "        print(\"\\n\".join(textwrap.wrap(line, width=width)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "We are using Anthropic Claude for text generation and Amazon Titan for text embedding.\n",
    "**Note:** \n",
    "Adding the model defintion in Langfuse will help in cost and usage tracking.\n",
    "We have added as a 'anthropic.claude-3-sonnet-20240229-v1:0' as Bedrock model definition for cost and usage tracking in Langfuse\n",
    "If time is available, we will show how to add model definition for 'amazon.titan-text-express-v1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/jczxmthn3sv88zhk4c_3j9lh0000gs/T/ipykernel_95303/1428557384.py:29: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import BedrockEmbeddings`.\n",
      "  bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_runtime)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")\n",
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Download some of the files to build our document store. For this example we will be using public IRS documents from [here](https://www.irs.gov/publications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1544.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p15.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1212.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading we can load the documents with the help of [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html) and splitting them into smaller chunks.\n",
    "\n",
    "Note: The retrieved document/text should be large enough to contain enough information to answer a question; but small enough to fit into the LLM prompt. Also the embeddings model has a limit of the length of input tokens limited to 8192 tokens, which roughly translates to ~32,000 characters. For the sake of this use-case we are creating chunks of roughly 1000 characters with an overlap of 100 characters using [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html).\n",
    "\n",
    "#### Next steps - to show how we can iterate through and create vector store. Skip this portion (as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents])//len(documents)\n",
    "avg_char_count_pre = avg_doc_length(documents)\n",
    "avg_char_count_post = avg_doc_length(docs)\n",
    "print(f'Average length among {len(documents)} documents loaded is {avg_char_count_pre} characters.')\n",
    "print(f'After the split we have {len(docs)} documents more than the original {len(documents)}.')\n",
    "print(f'Average length among {len(docs)} documents (after split) is {avg_char_count_post} characters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had 3 PDF documents which have been split into smaller ~500 chunks.\n",
    "\n",
    "Now we can see how a sample embedding would look like for one of those chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    sample_embedding = np.array(bedrock_embeddings.embed_query(docs[0].page_content))\n",
    "    print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "    print(\"Size of the embedding: \", sample_embedding.shape)\n",
    "\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Continue ...] Use VectorStoreIndexWrapper to create vector store\n",
    "\n",
    "Following the similar pattern, embeddings could be generated for the entire corpus and stored in a vector store.\n",
    "\n",
    "This can be easily done using [FAISS](https://github.com/facebookresearch/faiss) implementation inside [LangChain](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html) which takes  input the embeddings model and the documents to create the entire vector store. Using the Index Wrapper we can abstract away most of the heavy lifting such as creating the prompt, getting embeddings of the query, sampling the relevant documents and calling the LLM. [VectorStoreIndexWrapper](https://python.langchain.com/en/latest/modules/indexes/getting_started.html#one-line-index-creation) helps us with that.\n",
    "\n",
    "**⚠️⚠️⚠️ NOTE: it might take few minutes to run the following cell ⚠️⚠️⚠️**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "\n",
    "\n",
    "@observe(as_type=\"generation\")\n",
    "def create_vector_store():\n",
    "    langfuse_context.update_current_observation(\n",
    "        name=\"Vector store creation\", input=\"PDF_Docs\", output=\"Vector_store\"\n",
    "    ) \n",
    "    langfuse_context.update_current_trace(\n",
    "        name=\"Vector store creation trace\",\n",
    "        session_id=\"Vector store creation session\",\n",
    "        tags=[\"embeddings\", \"vector_store\"],\n",
    "        public=True\n",
    "    )    \n",
    "    vectorstore_faiss = FAISS.from_documents(\n",
    "                            docs,\n",
    "                            bedrock_embeddings,\n",
    "                      )\n",
    "    return vectorstore_faiss\n",
    "vectorstore_faiss = create_vector_store()\n",
    "wrapper_store_faiss = VectorStoreIndexWrapper(vectorstore=vectorstore_faiss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answer - Traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_name = \"RAG_Trace001\"\n",
    "session_id = \"RAG_Session001\"\n",
    "user_id = \"Developer_RAG001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "@observe()\n",
    "def invokeLLM(rag_chain, question):\n",
    "    langfuse_handler = CallbackHandler()   \n",
    "    # adding Langfuse context\n",
    "    langfuse_context.update_current_trace(\n",
    "        name=trace_name, \n",
    "        session_id=session_id,\n",
    "        user_id=user_id, \n",
    "    )      \n",
    "    langfuse_handler=langfuse_context.get_current_langchain_handler()       \n",
    "    result = rag_chain.invoke({\"input\": question},config={\"callbacks\": [langfuse_handler]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR QUERY HERE ...\n",
    "question = \"What is the difference between market discount and qualified stated interest?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is the difference between market discount and qualified stated interest?',\n",
      "'context': [Document(metadata={'source': 'data/p1212.pdf', 'page': 2}, page_content=\"was less than\n",
      "the debt instrument's issue price \\nplus the total OID that accrued before you ac-\\nquired it. The\n",
      "market discount is the difference \\nbetween the issue price plus accrued OID and \\nyour adjusted\n",
      "basis.\\nPremium. A debt instrument is purchased at a \\npremium if its adjusted basis immediately\n",
      "after \\npurchase is greater than the total of all amounts \\npayable on the debt instrument after the\n",
      "pur-\\nchase date, other than qualified stated interest. \\nThe premium is the excess of the adjusted\n",
      "ba-\\nsis over the payable amounts.\\nPremium will generally eliminate the future \\nreporting of OID\n",
      "in income by the purchaser, as \\ndiscussed under Information for Owners of OID \\nDebt Instruments ,\n",
      "later. See Pub. 550  for more \\ninformation on the tax treatment of bond pre-\\nmium.\\nQualified\n",
      "stated interest.  In general, qualified \\nstated interest is stated interest that is\n",
      "uncondi-\\ntionally payable in cash or property (other than \\ndebt instruments of the issuer) at\n",
      "least annually\"), Document(metadata={'source': 'data/p1212.pdf', 'page': 5}, page_content='ket\n",
      "discount includible in income in box 5 of \\nForm 1099 -OID if you notify your broker in writ-\\ning\n",
      "that you elect to include market discount in \\nincome as it accrues. Unless you notify your \\nbroker\n",
      "in writing that you have not elected to \\nuse a constant yield method under section \\n1276(b) to\n",
      "determine accruals of market dis-\\ncount, your broker will use a constant yield \\nmethod to\n",
      "determine accruals of market dis-\\ncount rather than a ratable method.\\nSee Market Discount Bonds\n",
      "in chapter 1 of \\nPub. 550  for information on how to figure ac-\\ncrued market discount and include\n",
      "it in your in-\\ncome currently and for other information about \\nmarket discount bonds.\\nIf you\n",
      "choose to use the constant yield \\nmethod to figure accrued market discount, also \\nsee Figuring OID\n",
      "on Long -T erm Debt Instru-\\nments , later. The constant yield method of figur-\\ning accrued OID,\n",
      "explained under Debt Instru-\\nments Issued After July 1, 1982, and Before \\n1985  or Debt\n",
      "Instruments Issued After 1984 , as'), Document(metadata={'source': 'data/p1212.pdf', 'page': 3},\n",
      "page_content='(weighted average of accepted auction bids) \\ndiscount price for the longest -maturity\n",
      "T-bill ma-\\nturing on the same date as the T -bill being re-\\ndeemed. This noncompetitive discount\n",
      "price is \\nthe issue price (expressed as a percent of prin-\\ncipal) shown in Section III-A.\\nA\n",
      "similar rule is used to figure the discount \\non short- term discount obligations issued by the\n",
      "\\norganizations listed in Section III -B through \\nSection III-F .\\nExample 1.  There are 13 -week\n",
      "and \\n26-week T -bills maturing on the same date as \\nthe T -bill being redeemed. The price actually\n",
      "\\npaid by the owner cannot be established by \\nowner or middleman records. Y ou treat as the \\nissue\n",
      "price of the T -bill the noncompetitive dis-\\ncount price (expressed as a percent of princi-\\npal)\n",
      "shown in Section III -A for a 26 -week bill \\nmaturing on the same date as the T -bill re-\\ndeemed.\n",
      "The interest you report on Form \\n1099- INT is the OID (per $1,000 of principal) \\nshown in Section\n",
      "III-A for that obligation.')], 'answer': \"Market discount refers to the situation where a debt\n",
      "instrument is purchased at a price below its adjusted issue price plus any accrued original issue\n",
      "discount (OID). The market discount is the difference between the issue price plus accrued OID and\n",
      "the purchaser's adjusted basis.\\n\\nQualified stated interest, on the other hand, is stated interest\n",
      "that is unconditionally payable in cash or property (other than debt instruments of the issuer) at\n",
      "least annually over the term of the debt instrument.\\n\\nIn essence, market discount represents a\n",
      "discount from the debt instrument's adjusted issue price at which it was purchased, while qualified\n",
      "stated interest refers to the periodic interest payments specified by the terms of the debt\n",
      "instrument that must be paid at least annually.\"}\n"
     ]
    }
   ],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "import bs4\n",
    "import json\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "retriever=vectorstore_faiss.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    )\n",
    "\n",
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "result = invokeLLM(rag_chain, question)\n",
    "print_ww(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "Now that we have executed Q n A interaction with LLM, let us examine the traces in Langfuse.\n",
    "# Thank You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flush Langfuse context (Clear off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK is async, make sure to await all requests\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query for similarity search [You can skip this, as these are more of verification steps]\n",
    "\n",
    "Now that we have our vector store in place, we can start asking questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"Is it possible that I get sentenced to jail due to failure in filings?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step would be to create an embedding of the query such that it could be compared with the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_embedding = vectorstore_faiss.embedding_function.embed_query(query)\n",
    "np.array(query_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this embedding of the query to then fetch relevant documents.\n",
    "Now our query is represented as embeddings we can do a similarity search of our query against our data store providing us with the most relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevant_documents = vectorstore_faiss.similarity_search_by_vector(query_embedding)\n",
    "print(f'{len(relevant_documents)} documents are fetched which are relevant to the query.')\n",
    "print('----')\n",
    "for i, rel_doc in enumerate(relevant_documents):\n",
    "    print_ww(f'## Document {i+1}: {rel_doc.page_content}.......')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the relevant documents, it's time to use the LLM to generate an answer based on these documents. \n",
    "\n",
    "We will take our inital prompt, together with our relevant documents which were retreived based on the results of our similarity search. We then by combining these create a prompt that we feed back to the model to get our result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge share\n",
    "You have the possibility to use the wrapper provided by LangChain which wraps around the Vector Store and takes input the LLM.\n",
    "This wrapper performs the following steps behind the scences:\n",
    "- Take the question as input\n",
    "- Create question embedding\n",
    "- Fetch relevant documents\n",
    "- Stuff the documents and the question into a prompt\n",
    "- Invoke the model with the prompt and generate the answer in a human readable manner."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
