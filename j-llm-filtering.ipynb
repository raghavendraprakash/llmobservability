{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Demo: Filtering Requests/Responses for Amazon Bedrock using Langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Context\n",
    "Previously we saw how you can trace through the requests and response. Understand the context of request, prompt that has accompanied the request. Here, we will demonstrate how you can use open souce library such as LLM guard in the context of Langfuse to control how you can pass the input to LLMs and control the output to the end users. This is particularly useful when you establish the organization-wide policy of Responsible AI guidelines. \n",
    "\n",
    "### Challenges\n",
    "- Do not send the request to LLM if the request is deemed to be classified as a banned topic\n",
    "- Anonymize the input before sending the request to LLM\n",
    "- Anonymize the output befor sending the response to the users\n",
    "\n",
    "### How\n",
    "Part 1 - We will use LLM Guard's capability to scan through the request and see if the request contains any word that is not approved by the organization. If so, do not send the request any further, just respond to the user that the the request is not safe to send to LLM.\n",
    "\n",
    "Part 2 - We will use LLM Guard's capability to anonymize and de-anonymize the text. This is particularly useful when you are working with the sensitive data such as Healthcare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Here is the high level implementation flow. Using LLM Guard library for filtering the requests and response. Langfuse is integrated to work with LLM Guard which is an open source library.\n",
    "More details here ... https://llm-guard.com/\n",
    "\n",
    "- **LLM (Large Language Model)**: Anthropic Claude V1 available through Amazon Bedrock\n",
    "  This model will be used to generate a screen play for a given situation.\n",
    "- **LLM Guard**: An Open source library\n",
    "- **Langfuse**: Inspect through Langfuse UI console for deeper analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install langchain langchain-community langchain-core langfuse boto3 llm-guard\n",
    "%pip install -U langchain-aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set credentials - for langchain and for langfuse\n",
    "import os\n",
    "os.system('export AWS_PROFILE=default')\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = 'pk-lf-c8ec60a4-3f7e-4e65-8eda-09e76f796b3f'\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = 'sk-lf-0ffdfee6-4e88-4110-85ef-b6e153382c81'\n",
    "os.environ[\"LANGFUSE_HOST\"] = 'http://localhost:3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import textwrap\n",
    "import os\n",
    "import boto3\n",
    "from typing import Optional\n",
    "from io import StringIO\n",
    "# External Dependencies:\n",
    "from botocore.config import Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def print_ww(*args, width: int = 100, **kwargs):\n",
    "    \"\"\"Like print(), but wraps output to `width` characters (default 100)\"\"\"\n",
    "    buffer = StringIO()\n",
    "    try:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        print(*args, **kwargs)\n",
    "        output = buffer.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = _stdout\n",
    "    for line in output.splitlines():\n",
    "        print(\"\\n\".join(textwrap.wrap(line, width=width)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Bedrock LLM\n",
    "We are setting bedrock runtime to us-east-1 region.\n",
    "- Selecting anthropic claude 3 sonnet, also have set the model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "model_kwargs =  { \n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "}\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    client=bedrock_runtime,\n",
    "    model_id=model_id,\n",
    "    model_kwargs=model_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering requests and response so that LLMs get sanitized input and users get sanitized output\n",
    "Library used: LLM Guard (https://llm-guard.com/)\n",
    "preamble directs LLM to bypass the specific content.\n",
    "Note that we have decorated anonymizing, de-anonymizing, invoking LLM - all with the decorator @observe. This helps us to deep dive on Langfuse UI to analyze and inspect further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the trace details for inspection\n",
    "trace_name = \"FilterTrace\"\n",
    "session_id = \"SecuritySession\"\n",
    "user_id = \"Developer_FILTER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prompt is being managed within Langfuse\n",
    "You can change the prompt and make them available as you modify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a prompt for Claude 3 and manage it through Langfuse\n",
    "Check Langfuse Prompt console; If the prompt is already there, Edit to show the LLM engineering capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_prompt = (\n",
    "    \"system: You are a screen play writer. \"\n",
    "    \"Use the situation provided as\"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Keep the screen play interesting.\"\n",
    "    \"\\n\\n\"\n",
    "    \"human: {input}\"\n",
    "    \n",
    ")\n",
    "\n",
    "langfuse.create_prompt(\n",
    "    name=\"screen-play-creator\",\n",
    "    prompt=str_prompt,\n",
    "    config={\n",
    "        \"model\":model_id,\n",
    "        \"temperature\": 0,\n",
    "    },\n",
    "    labels=[\"production\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: You are a screen play writer. Use the situation provided as the question. Be creative. Keep the screen play interesting.\n",
      "\n",
      "human: {input}\n"
     ]
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    " \n",
    "langfuse = Langfuse()\n",
    "# Get current production version of prompt\n",
    "langfuse_prompt = langfuse.get_prompt(\"screen-play-creator\")\n",
    "print(langfuse_prompt.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-09-09 17:26:31\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized classification model\u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='cpu')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='MoritzLaurer/roberta-base-zeroshot-v2.0-c', subfolder='', revision='d825e740e0c59881cf0b0b1481ccf726b6d65341', onnx_path='protectai/MoritzLaurer-roberta-base-zeroshot-v2.0-c-onnx', onnx_revision='fde5343dbad32f1a5470890505c72ec656db6dbe', onnx_subfolder='', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'return_token_type_ids': False, 'max_length': 512, 'truncation': True}, tokenizer_kwargs={})\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langfuse.decorators import observe, langfuse_context\n",
    "from llm_guard.input_scanners import BanTopics\n",
    "#from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "from llm_guard.vault import Vault\n",
    "from llm_guard.input_scanners import Anonymize\n",
    "from llm_guard.input_scanners.anonymize_helpers import BERT_LARGE_NER_CONF\n",
    "from langfuse.decorators import observe, langfuse_context\n",
    "from llm_guard.output_scanners import Deanonymize\n",
    "\n",
    "vault = Vault()\n",
    "\n",
    "topic_scanner = BanTopics(topics=[\"violence\"], threshold=0.25)\n",
    "\n",
    "@observe()\n",
    "def anonymize(input: str):\n",
    "  scanner = Anonymize(vault, preamble=\"Insert before prompt\", allowed_names=[\"Priya Dube\"],\n",
    "                    recognizer_conf=BERT_LARGE_NER_CONF, language=\"en\")\n",
    "  sanitized_prompt, is_valid, risk_score = scanner.scan(input)\n",
    "  return sanitized_prompt\n",
    " \n",
    "@observe()\n",
    "def deanonymize(sanitized_prompt: str, answer: str):\n",
    "  scanner = Deanonymize(vault)\n",
    "  sanitized_model_output, is_valid, risk_score = scanner.scan(sanitized_prompt, answer)\n",
    "\n",
    "  return sanitized_model_output\n",
    "    \n",
    "@observe()\n",
    "def invokeLLMWithSecurityFilter(question):\n",
    "    sanitized_prompt, is_valid, risk_score = topic_scanner.scan(question)\n",
    "\n",
    "    print(sanitized_prompt)\n",
    "    print(is_valid)\n",
    "    print(risk_score)\n",
    "\n",
    "    langfuse_context.score_current_observation(\n",
    "        name=question,\n",
    "        value=risk_score\n",
    "    )\n",
    " \n",
    "    if(risk_score>0.4):\n",
    "        return \"This is not child safe, please request another topic\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())\n",
    "    \n",
    "    langfuse_handler = CallbackHandler()   \n",
    "    # adding Langfuse context\n",
    "    langfuse_context.update_current_trace(\n",
    "        name=trace_name, \n",
    "        session_id=session_id,\n",
    "        user_id=user_id, \n",
    "    )      \n",
    "    langfuse_handler=langfuse_context.get_current_langchain_handler()      \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    # anonymize\n",
    "    a_question = anonymize(question)\n",
    "    result = chain.invoke({\"input\": question},config={\"callbacks\": [langfuse_handler]})\n",
    "    \n",
    "    #de-anonymize - I want to send de-anonymized response\n",
    "    #sanitized_output = deanonymize(a_question, result)\n",
    "    #return sanitized_output\n",
    "    \n",
    "    #anonymize result - I want to send anonymized response\n",
    "    return anonymize(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate the filterning of banned content\n",
    "**Responsible AI 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-09-09 17:26:35\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNo banned topics detected     \u001b[0m \u001b[36mscores\u001b[0m=\u001b[35m{'violence': 0.09190163016319275}\u001b[0m\n",
      "With Atul Agnihotri as a director of the movie, give me a screen play on The Laughing Buddha\n",
      "True\n",
      "0.0\n",
      "\u001b[2m2024-09-09 17:26:35\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNo entity types provided, using default\u001b[0m \u001b[36mdefault_entities\u001b[0m=\u001b[35m['CREDIT_CARD', 'CRYPTO', 'EMAIL_ADDRESS', 'IBAN_CODE', 'IP_ADDRESS', 'PERSON', 'PHONE_NUMBER', 'US_SSN', 'US_BANK_NUMBER', 'CREDIT_CARD_RE', 'UUID', 'EMAIL_ADDRESS_RE', 'US_SSN_RE']\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized NER model         \u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='cpu')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='dslim/bert-large-NER', subfolder='', revision='13e784dccceca07aee7a7aab4ad487c605975423', onnx_path='dslim/bert-large-NER', onnx_revision='13e784dccceca07aee7a7aab4ad487c605975423', onnx_subfolder='onnx', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'aggregation_strategy': 'simple', 'ignore_labels': ['O', 'CARDINAL']}, tokenizer_kwargs={'model_input_names': ['input_ids', 'attention_mask']})\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mCREDIT_CARD_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mUUID\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mEMAIL_ADDRESS_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mUS_SSN_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mBTC_ADDRESS\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mURL_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mCREDIT_CARD\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mEMAIL_ADDRESS_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPHONE_NUMBER_ZH\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPHONE_NUMBER_WITH_EXT\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mDATE_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mTIME_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mHEX_COLOR\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPRICE_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:36\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPO_BOX_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:37\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFound sensitive data in the prompt and replaced it\u001b[0m \u001b[36mmerged_results\u001b[0m=\u001b[35m[type: PERSON, start: 5, end: 19, score: 0.9700000286102295]\u001b[0m \u001b[36mrisk_score\u001b[0m=\u001b[35m0.97\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:55\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mNo entity types provided, using default\u001b[0m \u001b[36mdefault_entities\u001b[0m=\u001b[35m['CREDIT_CARD', 'CRYPTO', 'EMAIL_ADDRESS', 'IBAN_CODE', 'IP_ADDRESS', 'PERSON', 'PHONE_NUMBER', 'US_SSN', 'US_BANK_NUMBER', 'CREDIT_CARD_RE', 'UUID', 'EMAIL_ADDRESS_RE', 'US_SSN_RE']\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-large-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mInitialized NER model         \u001b[0m \u001b[36mdevice\u001b[0m=\u001b[35mdevice(type='cpu')\u001b[0m \u001b[36mmodel\u001b[0m=\u001b[35mModel(path='dslim/bert-large-NER', subfolder='', revision='13e784dccceca07aee7a7aab4ad487c605975423', onnx_path='dslim/bert-large-NER', onnx_revision='13e784dccceca07aee7a7aab4ad487c605975423', onnx_subfolder='onnx', onnx_filename='model.onnx', kwargs={}, pipeline_kwargs={'batch_size': 1, 'device': device(type='cpu'), 'aggregation_strategy': 'simple', 'ignore_labels': ['O', 'CARDINAL']}, tokenizer_kwargs={'model_input_names': ['input_ids', 'attention_mask']})\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mCREDIT_CARD_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mUUID\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mEMAIL_ADDRESS_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mUS_SSN_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mBTC_ADDRESS\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mURL_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mCREDIT_CARD\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mEMAIL_ADDRESS_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPHONE_NUMBER_ZH\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPHONE_NUMBER_WITH_EXT\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mDATE_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mTIME_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mHEX_COLOR\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPRICE_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:56\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mLoaded regex pattern          \u001b[0m \u001b[36mgroup_name\u001b[0m=\u001b[35mPO_BOX_RE\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:57\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1msplitting the text into chunks\u001b[0m \u001b[36mlength\u001b[0m=\u001b[35m3093\u001b[0m \u001b[36mmodel_max_length\u001b[0m=\u001b[35m512\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mLOCATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mLOCATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mLOCATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mLOCATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mLOCATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mLOCATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mLOCATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mIgnoring entity               \u001b[0m \u001b[36mentity_group\u001b[0m=\u001b[35mORGANIZATION\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mremoving element type: PERSON, start: 2824, end: 2827, score: 0.949999988079071 from results list due to merge\u001b[0m\n",
      "\u001b[2m2024-09-09 17:26:59\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mFound sensitive data in the prompt and replaced it\u001b[0m \u001b[36mmerged_results\u001b[0m=\u001b[35m[type: PERSON, start: 74, end: 88, score: 0.9700000286102295, type: PERSON, start: 306, end: 307, score: 0.8100000023841858, type: PERSON, start: 479, end: 485, score: 0.9599999785423279, type: PERSON, start: 1021, end: 1024, score: 0.7300000190734863, type: PERSON, start: 1148, end: 1150, score: 0.9700000286102295, type: PERSON, start: 1171, end: 1177, score: 0.8999999761581421, type: PERSON, start: 1289, end: 1291, score: 0.8700000047683716, type: PERSON, start: 1449, end: 1455, score: 0.8799999952316284, type: PERSON, start: 1663, end: 1669, score: 0.8299999833106995, type: PERSON, start: 1766, end: 1772, score: 0.7900000214576721, type: PERSON, start: 1782, end: 1783, score: 0.8100000023841858, type: PERSON, start: 1900, end: 1906, score: 0.8500000238418579, type: PERSON, start: 2029, end: 2035, score: 0.8700000047683716, type: PERSON, start: 2188, end: 2194, score: 0.8999999761581421, type: PERSON, start: 2232, end: 2238, score: 0.8399999737739563, type: PERSON, start: 2381, end: 2387, score: 0.8999999761581421, type: PERSON, start: 2548, end: 2554, score: 0.8899999856948853, type: PERSON, start: 2604, end: 2607, score: 0.9800000190734863, type: PERSON, start: 2618, end: 2624, score: 0.8600000143051147, type: PERSON, start: 2672, end: 2678, score: 0.8600000143051147, type: PERSON, start: 2756, end: 2762, score: 0.9200000166893005, type: PERSON, start: 2800, end: 2801, score: 0.6399999856948853, type: PERSON, start: 2801, end: 2803, score: 0.5, type: PERSON, start: 2824, end: 2830, score: 0.949999988079071, type: PERSON, start: 2939, end: 2954, score: 0.6399999856948853, type: PERSON, start: 3000, end: 3006, score: 0.9399999976158142]\u001b[0m \u001b[36mrisk_score\u001b[0m=\u001b[35m0.98\u001b[0m\n",
      "Insert before promptHere's a screenplay for a movie titled \"The Laughing Buddha,\" directed by\n",
      "[REDACTED_PERSON_1]:\n",
      "\n",
      "FADE IN:\n",
      "\n",
      "INT. ANCIENT BUDDHIST MONASTERY - DAY\n",
      "\n",
      "A serene and timeless monastery nestled in the Himalayan mountains. MONK TENZIN (60s), a wise and\n",
      "gentle soul, sits in meditation, surrounded by young novice monks.\n",
      "\n",
      "[REDACTED_PERSON_2]ENZIN\n",
      "(opening his eyes)\n",
      "My dear students, today we explore the teachings of the Laughing Buddha, the embodiment of joy and\n",
      "enlightenment.\n",
      "\n",
      "EXT. MONASTERY COURTYARD - DAY\n",
      "\n",
      "[REDACTED_PERSON_3] leads the novice monks through the courtyard, stopping before a large statue of\n",
      "a jovial, rotund Buddha with a beaming smile.\n",
      "\n",
      "TENZIN\n",
      "The Laughing Buddha reminds us that true happiness comes from within, not from material possessions\n",
      "or fleeting pleasures.\n",
      "\n",
      "NOVICE MONK\n",
      "But Master, how can one find such joy amidst the suffering in the world?\n",
      "\n",
      "TENZIN\n",
      "(smiling)\n",
      "A valid question, my child. The Laughing Buddha teaches us to embrace life's challenges with a light\n",
      "heart and an open mind.\n",
      "\n",
      "SMASH CUT TO:\n",
      "\n",
      "EXT. BUSTLING CITY STREET - DAY\n",
      "\n",
      "[REDACTED_PERSON_4]ESH (30s), a stressed-out corporate executive, rushes through the crowded\n",
      "streets, oblivious to the world around him.\n",
      "\n",
      "INT. [REDACTED_PERSON_5]JESH'S OFFICE - DAY\n",
      "\n",
      "[REDACTED_PERSON_6] sits at his desk, buried under paperwork and ringing phones. His life is a\n",
      "whirlwind of deadlines and stress.\n",
      "\n",
      "[REDACTED_PERSON_5]JESH\n",
      "(on the phone)\n",
      "No, I don't care about the budget! Just get it done!\n",
      "\n",
      "He slams down the phone, rubbing his temples in frustration.\n",
      "\n",
      "EXT. CITY PARK - DAY\n",
      "\n",
      "[REDACTED_PERSON_6] sits on a bench, lost in thought. A STREET VENDOR (50s) approaches, carrying a\n",
      "tray of small Buddha statues.\n",
      "\n",
      "STREET VENDOR\n",
      "Sir, would you like to buy a Laughing Buddha? They bring good luck and happiness.\n",
      "\n",
      "[REDACTED_PERSON_6] waves him off dismissively, but the vendor persists, placing a small statue on\n",
      "the bench beside [REDACTED_PERSON_6].\n",
      "\n",
      "STREET [REDACTED_PERSON_7]ENDOR\n",
      "(smiling)\n",
      "Happiness is a choice, my friend. The Laughing Buddha reminds us to find joy in the present moment.\n",
      "\n",
      "[REDACTED_PERSON_6] picks up the statue, studying its cheerful expression with curiosity.\n",
      "\n",
      "SMASH CUT TO:\n",
      "\n",
      "EXT. HIMALAYAN MOUNTAIN PATH - DAY\n",
      "\n",
      "[REDACTED_PERSON_6], carrying a backpack, hikes along a winding mountain path, the Laughing Buddha\n",
      "statue peeking out from his bag.\n",
      "\n",
      "EXT. ANCIENT BUDDHIST MONASTERY - DAY\n",
      "\n",
      "[REDACTED_PERSON_6] arrives at the monastery, greeted by [REDACTED_PERSON_3] and the novice monks.\n",
      "\n",
      "TENZIN\n",
      "Welcome, my friend. You have come seeking the wisdom of the Laughing Buddha.\n",
      "\n",
      "Over the course of several weeks, [REDACTED_PERSON_6] immerses himself in the teachings of the\n",
      "Laughing Buddha, learning to let go of his attachment to material success and embrace the present\n",
      "moment.\n",
      "\n",
      "MONTAGE:\n",
      "\n",
      "- [REDACTED_PERSON_6] meditates with the monks, finding inner peace.\n",
      "- [REDACTED_PERSON_8]zin guides [REDACTED_PERSON_6] through simple acts of kindness and service.\n",
      "- [REDACTED_PERSON_6] laughs and smiles, his stress melting away.\n",
      "\n",
      "EXT. MONASTERY COURTYARD - DAY\n",
      "\n",
      "[REDACTED_PERSON_6] stands before the Laughing Buddha sta[REDACTED_PERSON_9][REDACTED_PERSON_10], a\n",
      "transformed man. [REDACTED_PERSON_3] approaches, placing a hand on his shoulder.\n",
      "\n",
      "TENZIN\n",
      "You have found the true joy that comes from within. The [REDACTED_PERSON_11]'s teachings will guide\n",
      "you on your journey.\n",
      "\n",
      "[REDACTED_PERSON_6] nods, a serene smile on his face as he embraces his newfound enlightenment.\n",
      "\n",
      "FADE OUT.\n"
     ]
    }
   ],
   "source": [
    "#YOUR QUERY HERE ...\n",
    "situation = \"With Atul Agnihotri as a director of the movie, give me a screen play on The Laughing Buddha\"\n",
    "result = invokeLLMWithSecurityFilter(situation)\n",
    "print_ww (result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstrate anonymize/de-anonymize capability\n",
    "**Responsible AI 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR QUERY HERE ...\n",
    "situation = \"Mr. Gregor, you can now submit your evidence for the theft charge. With this, create a screen play\"\n",
    "result = invokeLLMWithSecurityFilter(situation)\n",
    "print_ww (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flush Langfuse context (Clear off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK is async, make sure to await all requests\n",
    "langfuse.flush()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
